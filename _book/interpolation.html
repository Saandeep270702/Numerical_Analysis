<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Interpolation | Numerical Analysis</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Interpolation | Numerical Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Interpolation | Numerical Analysis" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Sai Saandeep.S, Dr. Sivaram" />


<meta name="date" content="2024-12-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="numerical-linear-algebra.html"/>
<link rel="next" href="quadratures.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#why-numerical-analysis"><i class="fa fa-check"></i><b>1.1</b> Why Numerical Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#representing-numbers-on-a-machine"><i class="fa fa-check"></i><b>1.2</b> Representing Numbers on a Machine</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#condition-number-of-a-problem"><i class="fa fa-check"></i><b>1.3</b> Condition Number of a Problem</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#vector-normsrecap"><i class="fa fa-check"></i><b>1.3.1</b> Vector Norms(Recap)</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#examples-on-finding-condition-number"><i class="fa fa-check"></i><b>1.3.2</b> Examples on finding Condition number</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html"><i class="fa fa-check"></i><b>2</b> Numerical Linear Algebra</a>
<ul>
<li class="chapter" data-level="2.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#columnspace-nullspace-and-all"><i class="fa fa-check"></i><b>2.1</b> Columnspace, Nullspace and all</a></li>
<li class="chapter" data-level="2.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#matrix-norms"><i class="fa fa-check"></i><b>2.2</b> Matrix Norms</a></li>
<li class="chapter" data-level="2.3" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#condition-number-of-matrix-vector-products"><i class="fa fa-check"></i><b>2.3</b> Condition number of Matrix vector products</a></li>
<li class="chapter" data-level="2.4" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#solving-linear-systems"><i class="fa fa-check"></i><b>2.4</b> Solving Linear Systems</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#special-matrices"><i class="fa fa-check"></i><b>2.4.1</b> Special Matrices</a></li>
<li class="chapter" data-level="2.4.2" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#general-case"><i class="fa fa-check"></i><b>2.4.2</b> General Case</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#solving-overdetermined-systems"><i class="fa fa-check"></i><b>2.5</b> Solving Overdetermined Systems</a></li>
<li class="chapter" data-level="2.6" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#solving-underdetermined-systems"><i class="fa fa-check"></i><b>2.6</b> Solving Underdetermined Systems</a></li>
<li class="chapter" data-level="2.7" data-path="numerical-linear-algebra.html"><a href="numerical-linear-algebra.html#iterative-methods-for-solving-linear-systems"><i class="fa fa-check"></i><b>2.7</b> Iterative Methods for solving Linear Systems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpolation.html"><a href="interpolation.html"><i class="fa fa-check"></i><b>3</b> Interpolation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="interpolation.html"><a href="interpolation.html#motivation---interpolation-vs.-approximation"><i class="fa fa-check"></i><b>3.1</b> Motivation - Interpolation vs. Approximation</a></li>
<li class="chapter" data-level="3.2" data-path="interpolation.html"><a href="interpolation.html#lagrange-interpolation"><i class="fa fa-check"></i><b>3.2</b> Lagrange Interpolation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="interpolation.html"><a href="interpolation.html#motivation"><i class="fa fa-check"></i><b>3.2.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2.2" data-path="interpolation.html"><a href="interpolation.html#lagrange-interpolant"><i class="fa fa-check"></i><b>3.2.2</b> Lagrange Interpolant</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="interpolation.html"><a href="interpolation.html#choice-of-nodes"><i class="fa fa-check"></i><b>3.3</b> Choice of Nodes</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="interpolation.html"><a href="interpolation.html#motivation-1"><i class="fa fa-check"></i><b>3.3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.3.2" data-path="interpolation.html"><a href="interpolation.html#fundamental-theorem-of-polynomial-interpolation"><i class="fa fa-check"></i><b>3.3.2</b> Fundamental Theorem of Polynomial Interpolation</a></li>
<li class="chapter" data-level="3.3.3" data-path="interpolation.html"><a href="interpolation.html#different-possible-types-of-nodes"><i class="fa fa-check"></i><b>3.3.3</b> Different Possible types of nodes</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="interpolation.html"><a href="interpolation.html#wierstrass-approximation-theorem"><i class="fa fa-check"></i><b>3.4</b> Wierstrass Approximation theorem</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="quadratures.html"><a href="quadratures.html"><i class="fa fa-check"></i><b>4</b> Quadratures</a>
<ul>
<li class="chapter" data-level="4.1" data-path="quadratures.html"><a href="quadratures.html#motivation-2"><i class="fa fa-check"></i><b>4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2" data-path="quadratures.html"><a href="quadratures.html#different-schemes"><i class="fa fa-check"></i><b>4.2</b> Different Schemes</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="quadratures.html"><a href="quadratures.html#basic-schemes"><i class="fa fa-check"></i><b>4.2.1</b> Basic Schemes</a></li>
<li class="chapter" data-level="4.2.2" data-path="quadratures.html"><a href="quadratures.html#accuracy-of-these-schemes"><i class="fa fa-check"></i><b>4.2.2</b> Accuracy of these schemes</a></li>
<li class="chapter" data-level="4.2.3" data-path="quadratures.html"><a href="quadratures.html#simpsons-rule"><i class="fa fa-check"></i><b>4.2.3</b> Simpson’s Rule</a></li>
<li class="chapter" data-level="4.2.4" data-path="quadratures.html"><a href="quadratures.html#trapezoidal-rule-with-end-point-corrections"><i class="fa fa-check"></i><b>4.2.4</b> Trapezoidal Rule with End point Corrections</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="quadratures.html"><a href="quadratures.html#euler-maclaurian-formula"><i class="fa fa-check"></i><b>4.3</b> Euler-Maclaurian Formula</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="quadratures.html"><a href="quadratures.html#introduction-1"><i class="fa fa-check"></i><b>4.3.1</b> Introduction</a></li>
<li class="chapter" data-level="4.3.2" data-path="quadratures.html"><a href="quadratures.html#formula-and-derivation"><i class="fa fa-check"></i><b>4.3.2</b> Formula and Derivation</a></li>
<li class="chapter" data-level="4.3.3" data-path="quadratures.html"><a href="quadratures.html#examples"><i class="fa fa-check"></i><b>4.3.3</b> Examples</a></li>
<li class="chapter" data-level="4.3.4" data-path="quadratures.html"><a href="quadratures.html#higher-order-quadratures"><i class="fa fa-check"></i><b>4.3.4</b> Higher Order Quadratures</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="quadratures.html"><a href="quadratures.html#gaussian-quadratures"><i class="fa fa-check"></i><b>4.4</b> Gaussian Quadratures</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html"><i class="fa fa-check"></i><b>5</b> Root Finding Algorithms</a>
<ul>
<li class="chapter" data-level="5.1" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html#motivation-3"><i class="fa fa-check"></i><b>5.1</b> Motivation</a></li>
<li class="chapter" data-level="5.2" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html#bisection-method"><i class="fa fa-check"></i><b>5.2</b> Bisection Method</a></li>
<li class="chapter" data-level="5.3" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html#newton-method"><i class="fa fa-check"></i><b>5.3</b> Newton Method</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html#rate-of-convergence"><i class="fa fa-check"></i><b>5.3.1</b> Rate of Convergence</a></li>
<li class="chapter" data-level="5.3.2" data-path="root-finding-algorithms.html"><a href="root-finding-algorithms.html#possibility-of-non-convergence"><i class="fa fa-check"></i><b>5.3.2</b> Possibility of Non-Convergence?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html"><i class="fa fa-check"></i><b>6</b> Numerical Differentiation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html#motivation-4"><i class="fa fa-check"></i><b>6.1</b> Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="numerical-differentiation.html"><a href="numerical-differentiation.html#finite-differences"><i class="fa fa-check"></i><b>6.2</b> Finite Differences</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html"><i class="fa fa-check"></i><b>7</b> Solving Ordinary Differential Equations Numerically</a>
<ul>
<li class="chapter" data-level="7.1" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#different-basic-methods"><i class="fa fa-check"></i><b>7.2</b> Different Basic Methods</a></li>
<li class="chapter" data-level="7.3" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#linear-stability-analysis"><i class="fa fa-check"></i><b>7.3</b> Linear Stability Analysis</a></li>
<li class="chapter" data-level="7.4" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#accuracy"><i class="fa fa-check"></i><b>7.4</b> Accuracy</a></li>
<li class="chapter" data-level="7.5" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#simple-pendulum---solving-system-of-odes"><i class="fa fa-check"></i><b>7.5</b> Simple Pendulum - Solving System of ODEs</a></li>
<li class="chapter" data-level="7.6" data-path="solving-ordinary-differential-equations-numerically.html"><a href="solving-ordinary-differential-equations-numerically.html#simple-pendulum---finite-difference-for-2nd-order-derivative"><i class="fa fa-check"></i><b>7.6</b> Simple Pendulum - Finite difference for 2nd order derivative</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Numerical Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpolation" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Interpolation<a href="interpolation.html#interpolation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="motivation---interpolation-vs.-approximation" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Motivation - Interpolation vs. Approximation<a href="interpolation.html#motivation---interpolation-vs.-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If the exact form of <span class="math inline">\(f(x)\)</span> is known, then we have full information about <span class="math inline">\(f(x)\)</span> i.e., Derivatives etc., But what if the exact form is not known?</p>
<p>Given points <span class="math inline">\(\{x_i\}_{i=1}^n\)</span> and functional values at those points <span class="math inline">\(f(x_1),f(x_2), \dots, f(x_n)\)</span>, we wish to find an Approximation to <span class="math inline">\(f(x)\)</span>. One way to approximate a function is by <em>interpolating</em> it.</p>
<blockquote>
<p>We say that <span class="math inline">\(p(x)\)</span> is an interpolant to <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(\{x_i\}_{i=1}^n\)</span> if <span class="math inline">\(p(x_i)= f(x_i)\)</span> for <span class="math inline">\(1\le i\le n\)</span>.</p>
</blockquote>
<p>Eg: A step function <span class="math inline">\(p(x) = f(x_i)\)</span> for <span class="math inline">\(x\in \left[ \frac{x_i+x_{i-1}}{2}, \frac{x_i+x_{i+1}}{2} \right]\)</span>.</p>
<p>The step function, though it is an interpolant, we don’t prefer it. The main issue is that it is not continuous. We prefer in some practical applications for the interpolant to be differentiable.</p>
<p>Note that not all approximations are interpolants.</p>
<p>Eg: A polynomial approximation to <span class="math inline">\(\sin x\)</span> is a truncated Taylor series after a few terms(say till degree <span class="math inline">\(2n+1\)</span>). This approximation is not an interpolant as it won’t intersect <span class="math inline">\(\sin x\)</span> at <span class="math inline">\(2n+2\)</span> points.</p>
<p>Assume <span class="math inline">\(f(x)\)</span> to be continuous. Consider the sequence of interpolants <span class="math inline">\(\{P_n(x)\}_{n=1}^{\infty}\)</span> converging to <span class="math inline">\(f(x)\)</span> on <span class="math inline">\([a,b]\)</span> such that <span class="math inline">\(P_n(x)=f(x) \ \  \ \forall x\in \{x_1,x_2,\dots,x_n \}\)</span></p>
<p><span class="math display" id="eq:integralfinterp">\[\begin{equation}
\tag{3.1}
\int_a^b f(x) \, dx \approx \int_a^b P_n(x) \, dx
\end{equation}\]</span></p>
<p><span class="math display" id="eq:dfdxinterp">\[\begin{equation}
\tag{3.2}
\frac{df}{dx}(x) \approx \frac{dP_n}{dx}(x)
\end{equation}\]</span></p>
<p>Equation<a href="interpolation.html#eq:integralfinterp">(3.1)</a> holds true if <span class="math inline">\(\{P_n(x)\}_{n=1}^{\infty}\)</span> converges to <span class="math inline">\(f(x)\)</span> <em>uniformly</em>.</p>
<p>Equation<a href="interpolation.html#eq:dfdxinterp">(3.2)</a> holds true if <span class="math inline">\(P_n&#39;(x)\)</span> exists and <span class="math inline">\(\{P&#39;_n(x)\}_{n=1}^{\infty}\)</span> converges to <span class="math inline">\(f&#39;(x)\)</span> <em>uniformly</em>.</p>
<p>In this course, we consider the interpolants <span class="math inline">\(p(x) \in C^{\infty}([a,b])\)</span>. A simplest such interpolant would be a polynomial.</p>
</div>
<div id="lagrange-interpolation" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Lagrange Interpolation<a href="interpolation.html#lagrange-interpolation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="motivation" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Motivation<a href="interpolation.html#motivation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider <span class="math inline">\(p(x) = a_0+a_1x+a_2x^2+\dots+ a_mx^m\)</span> to be a polynomial interpolant for <span class="math inline">\(f(x)\)</span> with <strong>node points</strong> as <span class="math inline">\(\{x_i\}_{i=1}^n\)</span>. Therefore,
<span class="math display">\[p(x_i)=f(x_i) \implies a_0+a_1x_i+a_2x_i^2+\dots+ a_mx_i^m = f(x_i) \ \ \ \forall i \in \{1,2,\cdots, n\}\]</span>.</p>
<p><span class="math display">\[\begin{equation}
\implies \begin{bmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^m\\
1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^m\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^m\\
\end{bmatrix}_{n \times(m+1)} \begin{bmatrix}a_0\\a_1\\ \vdots \\a_m \end{bmatrix}_{(m+1) \times 1}  = \begin{bmatrix} f(x_1)\\f(x_2)\\ \vdots \\f(x_n) \end{bmatrix}_{n\times 1}
\end{equation}\]</span></p>
<p>Let <span class="math display">\[X = \begin{bmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \cdots &amp; x_1^m\\
1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^m\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^m\\
\end{bmatrix}\text{ ,} \ \  \ \bar{a} = \begin{bmatrix}a_0\\a_1\\ \vdots \\a_m \end{bmatrix}  \text{ and } \ \ \ \bar{f}=  \begin{bmatrix} f(x_1)\\f(x_2)\\ \vdots \\f(x_n) \end{bmatrix}\]</span>
<span class="math display">\[\implies X\bar{a} = \bar{f}\]</span></p>
<p>Now the <span class="math inline">\(\bar{a}\)</span> has the coefficients of the interpolant. To find the coefficients, we need to solve the linear system.</p>
<p>If <span class="math inline">\(m+1&lt;n\)</span> then <span class="math inline">\(X\)</span> is a thin matrix. i.e., we have lesser number of variables than equations. Therefore, solution may not exist. i.e., we may not be able to find <span class="math inline">\(p(x)\)</span>.</p>
<p>If <span class="math inline">\(m+1&gt;n\)</span> then <span class="math inline">\(X\)</span> is a fat matrix. Infinitely many polynomial interpolants exist.</p>
<p>If <span class="math inline">\(m+1=n\)</span> then <span class="math inline">\(X\)</span> is a square matrix. <span class="math inline">\(X\)</span> is Vandermonde matrix. It can be shown that:
<span class="math display">\[\det(X) = \prod_{1\le i&lt;j\le n}(x_i-x_j)\]</span>
If <span class="math inline">\(x_i&#39;s\)</span> are distinct then <span class="math inline">\(\det(X)\neq 0 \implies X\)</span> is invertible.</p>
<p><span class="math inline">\(\implies X\bar{a} = \bar{f}\)</span> has a unique solution for <span class="math inline">\(m+1=n\)</span>.</p>
<p><span class="math inline">\(\implies p(x)\)</span> interpolates <span class="math inline">\(f(x)\)</span> uniquely if <span class="math inline">\(\deg(p(x)) = n-1\)</span>.</p>
<p>Thus, the minimum degree of the interpolant polynomial is <span class="math inline">\(n-1\)</span>.</p>
<p><span class="math inline">\(p(x)\)</span> interpolates <span class="math inline">\(f(x)\)</span> uniquely if <span class="math inline">\(\deg(p(x))=n-1\)</span>. Thus, solving the equation <span class="math inline">\(X\bar{a} = \bar{f}\)</span>.
But there are issues in solving the linear system like this.</p>
<ul>
<li>Computational complexity in solving the linear system <span class="math inline">\(\mathcal{O}(n^3)\)</span>.</li>
<li>Condition number of <span class="math inline">\(X\)</span> grows exponentially in <span class="math inline">\(n\)</span>. This is not preferred as this might cause large errors with small error in input(say due to roundoff errors etc.,)</li>
</ul>
<p>To overcome these problems, we use Lagrange interpolation.</p>
</div>
<div id="lagrange-interpolant" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Lagrange Interpolant<a href="interpolation.html#lagrange-interpolant" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider</p>
<p><span class="math display">\[\begin{equation}
g(x_i) = \begin{cases}
        1 &amp; \text{if } i\neq j\\
        0 &amp; \text{if } i=j
    \end{cases}
\end{equation}\]</span>
for <span class="math inline">\(i,j \in \{1,2,\dots,n\}\)</span>. We are interested to find a polynomial interpolant for this. Let us consider the case of <span class="math inline">\(n=3\)</span> points and <span class="math inline">\(j=2\)</span>. i.e., <span class="math inline">\(g(x_1)=g(x_3)=0\)</span> and <span class="math inline">\(g(x_2)=1\)</span> for simplicity. The least degree of the polynomial interpolant <span class="math inline">\(p(x)\)</span> is <span class="math inline">\(n-1=2\)</span>. By intuition, we can say that <span class="math inline">\((x-x_1)(x-x_3)\)</span> is a factor of interpolant <span class="math inline">\(p(x)\)</span>. As <span class="math inline">\(p(x_2)=g(x_2)=1\)</span>, we can say that the interpolant <span class="math inline">\(p(x)\)</span> is:
<span class="math display">\[\begin{equation}
p(x) = \frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)}
\end{equation}\]</span></p>
<p>For <span class="math inline">\(n\)</span> points, we have the interpolant polynomial to <span class="math inline">\(g(x)\)</span> as:
<span class="math display">\[\begin{equation}
p(x) = l_j(x) = \prod_{\substack{i=0 \\ i\neq j}} \frac{x-x_i}{x_j-x_i}
\end{equation}\]</span></p>
<p><span class="math inline">\(l_j(x)\)</span> is a polynomial of degree <span class="math inline">\(n-1\)</span> such that:
<span class="math display">\[l_j(x_i) = \delta_{ij}\]</span>
Now consider <span class="math inline">\(n\)</span> node points <span class="math inline">\(\{f(x_i)\}_{i=1}^n\)</span> and consider the polynomial <span class="math inline">\(p(x)\)</span> defined as:
<span class="math display">\[\begin{equation}
p(x) = \sum_{j=1}^n f(x_j) l_j(x)
\end{equation}\]</span></p>
<p><span class="math inline">\(p(x)\)</span> is a polynomial of degree atmost <span class="math inline">\(n-1\)</span>. Now,</p>
<p><span class="math display">\[p(x_i) = \sum_{j=1}^n f(x_j) l_j(x_i) = \sum_{j=1}^n f(x_j) \delta_{ij} = f(x_i)\]</span>
This implies that <span class="math inline">\(p(x)\)</span> is an interpolant. This is known as <em>Lagrange Interpolant</em>.</p>
</div>
</div>
<div id="choice-of-nodes" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Choice of Nodes<a href="interpolation.html#choice-of-nodes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="motivation-1" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Motivation<a href="interpolation.html#motivation-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now after finding the interpolant, the next question to be asked is how accurate is the interpolant? Immediate obvious answer would be the numer of points chosen. But are there any other factors which determine the accuracy of the interpolant?</p>
<p>Example: Consider the function <span class="math inline">\(f(x) = \frac{1}{1+25x^2}\)</span> and the interpolation nodes as uniform nodes from [-1,1].</p>
<p><strong>INSERT CODE HERE</strong></p>
<p>We can see that the interpolant is not converging to <span class="math inline">\(f(x)\)</span> uniformly. There are some <strong><em>boundary effects</em></strong></p>
<p>Thus, selection of node points is also important. The question to ask now is what set of nodes guarantees uniform convergence?</p>
</div>
<div id="fundamental-theorem-of-polynomial-interpolation" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Fundamental Theorem of Polynomial Interpolation<a href="interpolation.html#fundamental-theorem-of-polynomial-interpolation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(f(x)\)</span> be a smooth function on [-1,1]. Let <span class="math inline">\(P_n(x)\)</span> be a polynomial interpolant to <span class="math inline">\(f(x)\)</span> at <span class="math inline">\(\{x_k\}_{k=0}^n\)</span> with atmost degree <span class="math inline">\(n\)</span>. Then <span class="math inline">\(\exists \, \zeta\in[-1,1]\)</span> such that:
<span class="math display">\[\begin{equation}
e(x) = f(x)-P_n(x) = \frac{f^{(n+1)}(\zeta)}{(n+1)!}\prod_{k=0}^n(x-x_k)
\end{equation}\]</span></p>
<p><strong>Proof:-</strong>
Define <span class="math display">\[w(x) := \prod_{k=0}^n(x-x_k)\]</span> and
<span class="math display">\[\begin{equation}
g_x(t) : = f(t)-P_n(t)-\left(\frac{f(x)-P_n(x)}{w(x)}\right)w(t)
\end{equation}\]</span>
where the subscript <span class="math inline">\(x\)</span> denotes that <span class="math inline">\(x\)</span> is fixed.</p>
<p><span class="math display">\[g_x(x) = f(x)-P_n(x)-\left(\frac{f(x)-P_n(x)}{w(x)}\right)w(x) = 0\]</span></p>
<p><span class="math display">\[g_x(x_j) = f(x_j)-P_n(x_j)-\left(\frac{f(x)-P_n(x)}{w(x)}\right)w(x_j)\]</span>
As <span class="math inline">\(P_n(x)\)</span> is an interpolant to <span class="math inline">\(f(x)\)</span> at nodes <span class="math inline">\(\{x_i\}_{i=0}^n\)</span>, <span class="math inline">\(P_n(x_j) = f(x_j)\)</span> and by definition <span class="math inline">\(w(x_j) =0\)</span>. Therefore, for <span class="math inline">\(j\in\{0,1,2,\dots ,n\}\)</span>, we have <span class="math inline">\(g_x(x_j)=0\)</span>.</p>
<p><span class="math inline">\(g_x(t)\)</span> is smooth in the interval (-1,1).</p>
<p>Define intervals
<span class="math display">\[\begin{align}
I_1     &amp;= [x_0,x_1]\\
I_2     &amp;= [x_1,x_2]\\
        &amp;\vdots\\
I_k     &amp;= [x_{k-1},x_k]\\
I_{k+1} &amp;= [x_k,x]\\
I_{k+2} &amp;=[x,x_{k+1}]\\
I_{k+3} &amp;= [x_{k+1},x_{k+2}]\\
        &amp;\vdots\\
I_{n+1} &amp;= [x_{n-1},x_n]
\end{align}\]</span>
According to Rolle’s theorem, <span class="math inline">\(g&#39;_x(t)\)</span> has atleast <span class="math inline">\(n+1\)</span> zeros on <span class="math inline">\([-1,1]\)</span>.
Again according to Rolle’s theorem, we can say that <span class="math inline">\(g&#39;&#39;_x(t)\)</span> has atleast <span class="math inline">\(n\)</span> zeros in <span class="math inline">\([-1,1]\)</span>. If we keep on using Rolle’s theorem for further <span class="math inline">\(n-1\)</span> times, we can show that <span class="math inline">\(g_x^{(n+1)}(t)\)</span> has atleast 1 zero on <span class="math inline">\([-1,1]\)</span> i.e., <span class="math inline">\(\exists \text{ a } \zeta\in[-1,1]\)</span> such that <span class="math inline">\(g_x^{(n+1)}(\zeta)=0\)</span></p>
<p><span class="math display">\[g^{(n+1)}_x(\zeta) = f^{(n+1)}(\zeta)-P^{(n+1)}_n(\zeta)-\left(\frac{f(x)-P_n(x)}{w(x)}\right)w^{(n+1)}(\zeta)\]</span></p>
<p>As <span class="math inline">\(P_n(t)\)</span> is an $n^th degree polynomial, <span class="math inline">\(P^{(n+1)}_n(\zeta)=0\)</span>.</p>
<p><span class="math display">\[w(t) = \prod_{k=0}^n(t-x_k)\implies w^{(n+1)}(t) = (n+1)!\]</span></p>
<p>Therefore <span class="math display">\[0 = f^{(n+1)}(\zeta)-0 - \left(\frac{f(x)-P_n(x)}{w(x)}\right)(n+1)!\]</span>
<span class="math display">\[\implies e(x) = f(x)-P_n(x) = \frac{f^{(n+1)}(\zeta)}{(n+1)!}w(x)= \frac{f^{(n+1)}(\zeta)}{(n+1)!}\prod_{k=0}^n(x-x_k)\]</span></p>
<blockquote>
<p>What if <span class="math inline">\(x\in[a,b]\)</span> instead of <span class="math inline">\(x\in[-1,1]\)</span>?</p>
</blockquote>
<p>We can use a linear mapping from <span class="math inline">\([a,b]\)</span> to <span class="math inline">\([-1,1]\)</span>.</p>
</div>
<div id="different-possible-types-of-nodes" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Different Possible types of nodes<a href="interpolation.html#different-possible-types-of-nodes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now the goal is to find the nodes which minimise the maximum absolute interpolation error i.e., <span class="math display">\[\min \max_{x\in[-1,1]} |e(x)|\]</span>. In general, we can also try finding nodes which minimise <span class="math inline">\(p\)</span>-norm of the interpolation error i.e., <span class="math inline">\(\min \lVert e(x) \rVert_p\)</span> where:
<span class="math display">\[\lVert e(x) \rVert_p = \left( \int_{-1}^1 |e(x)|^p \, dx\right)^{\frac{1}{p}}\]</span> and <span class="math display">\[\lim_{p\to\infty} \lVert e(x) \rVert_p = \max_{x\in[-1,1]}|e(x)|\]</span></p>
<p>Now the issue is it is difficult to know about <span class="math inline">\(f^{(n+1)}(\zeta)\)</span> as <span class="math inline">\(f(x)\)</span> is not known always. Now the best thing we can do is to find nodes which minimise <span class="math display">\[\min \max_{x\in[-1,1]}\left|\prod_{k=0}^n(x-x_k)\right| \text{ or } \min \lVert \prod_{k=0}^n(x-x_k) \rVert_p\]</span>.</p>
<p>It turns out that Legendre nodes minimise <span class="math inline">\(||w(x)||_2\)</span>, Chebyshev nodes of first kind minimise <span class="math inline">\(||w(x)||_{\infty}\)</span> and Chebyshev nodes of second kind minimises <span class="math inline">\(||w(x)||_1\)</span>.</p>
<div id="legendre-nodes" class="section level4 hasAnchor" number="3.3.3.1">
<h4><span class="header-section-number">3.3.3.1</span> Legendre Nodes<a href="interpolation.html#legendre-nodes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Monic Legendre polynomials are defined as:
<span class="math display">\[q_0(x) = 1, \, \, q_1(x) = x\]</span>
<span class="math inline">\(q_n(x)\)</span> is a monic polynomial of degree <span class="math inline">\(n\)</span> such that:
<span class="math display">\[\begin{equation}
\int_{-1}^1 q_n(x) q_m(x) \, dx = 0 \ \  \ \forall \,  m\neq n
\end{equation}\]</span></p>
<p>First few monic Legendre polynomials are:
<span class="math display">\[\begin{align*}
  q_0(x) &amp;= 1\\
  q_1(x) &amp;= x\\
  q_2(x) &amp;= x^2-\frac{1}{3}\\
  q_3(x) &amp;= x^3-\frac{3}{5}x\\
  q_4(x) &amp;= x^4- \frac{6}{7}x^2+\frac{3}{35}
\end{align*}\]</span></p>
<p>The zeros of these Legendre polynomials are called Legendre nodes. Legendre nodes minimise <span class="math inline">\(||w(x)||_2\)</span>.</p>
</div>
<div id="chebyshev-nodes-of-first-kind" class="section level4 hasAnchor" number="3.3.3.2">
<h4><span class="header-section-number">3.3.3.2</span> Chebyshev nodes of first kind<a href="interpolation.html#chebyshev-nodes-of-first-kind" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Chebyshev polynomials of first kind are given by <span class="math inline">\(T_n(x) = \cos(n\cos^{-1}(x))\)</span>.</p>
<p>First few Chebyshev polynomials are:
<span class="math display">\[\begin{align}
T_0(x) &amp;= 1\\
T_1(x) &amp;= x\\
T_2(x) &amp;= 2x^2-1\\
T_3(x) &amp;= 4x^3-3x\\
T_4(x) &amp;= 8x^4-8x^2+1
\end{align}\]</span></p>
<p>An interesting property of these polynomials are <span class="math inline">\(T_m(x)\)</span> and <span class="math inline">\(T_n(x)\)</span> are orthogonal weighted by <span class="math inline">\(\frac{1}{\sqrt{1-x^2}}\)</span>.</p>
<p><span class="math display">\[\begin{align}
   \int_{-1}^{1}\frac{ T_n(x)T_m(x)}{\sqrt{1-x^2}}dx &amp;= 0 , m \neq n\\
                                    &amp;= \pi,m = n= 0\\
                                    &amp;= \frac{\pi}{2}, m = n \neq 0               
\end{align}\]</span></p>
<p><strong>Proof:-</strong></p>
<p>Let <span class="math inline">\(x = \cos \theta\)</span> where <span class="math inline">\(\theta \in [0,\pi]\)</span>. This implies that <span class="math inline">\(dx = -\sin \theta \, d \theta = -\sqrt{1-x^2} \, d \theta\)</span>. And <span class="math inline">\(x=-1 \implies \theta = \pi\)</span> and <span class="math inline">\(x =1 \implies \theta = 0\)</span>. Therefore,
<span class="math display">\[\begin{align*}
\int_{-1}^{1} T_m(x)T_n(x) \frac{1}{\sqrt{1-x^2}} dx &amp; = \int_{0}^{\pi} \cos(m\theta) \cos(n\theta) d\theta \\
&amp;= \frac{1}{2}{\int_{0}^{\pi}} \cos(m+n)\theta
+ \cos(m-n)\theta d\theta  \\
&amp;=\frac{1}{2} \left[\sin\frac{(m+n)\theta }{m+n}\right]_{0}^{\pi}
+ \left[\sin\frac{(m-n)\theta }{m-n}\right]_{0}^{\pi}\\
&amp;= 0, \text{ if } m \neq n
\end{align*}\]</span></p>
<p>Similarly with appropriate substitution, conditions for $m = n=0 $ and $m = n $ can be proved.</p>
<p>The zeros of Chebyshev polynomial <span class="math inline">\(T_{n+1}(x)\)</span> are given by <span class="math inline">\(x_k = \cos\left( \frac{2k+1}{2n+2} \pi \right)\)</span> where <span class="math inline">\(k \in \{ 0,1,2,\cdots,n \}\)</span>.</p>
<p><strong>Proof:-</strong></p>
<p>We have <span class="math display">\[T_{n+1}(x) = \cos((n+1)\arccos(x))\]</span>
<span class="math display">\[T_{n+1}(x) = 0 \implies \cos((n+1)\arccos(x)) = 0\]</span></p>
<p><span class="math display">\[\implies(n+1) \arccos(x) = (2k+1)\frac{\pi}{2} \ \ \ k \in \mathbb{Z}\]</span></p>
<p><span class="math display">\[\implies \arccos(x) = (2k+1)\frac{\pi}{2(n+1)} \ \ \ \ k \in \mathbb{Z}\]</span></p>
<p>But as the principle range of <span class="math inline">\(\arccos(x)\)</span> is defined as <span class="math inline">\([0,\pi]\)</span>, we must restrict the values <span class="math inline">\(k\)</span> can take.</p>
<p><span class="math display">\[0 \le (2k+1)\frac{\pi}{2(n+1)} \le \pi \implies 0 \le k \le n+\frac{1}{2} \]</span></p>
<p>But as <span class="math inline">\(k \in \mathbb{Z}\)</span>, we can say that the possible values <span class="math inline">\(k\)</span> can take are <span class="math inline">\(\{ 0,1,2,\cdots,n\}\)</span>.</p>
<p>Therefore <span class="math inline">\(\arccos(x_k) = (2k+1)\frac{\pi}{2(n+1)} \ \ \ \ k \in \{ 0,1,2,\cdots,n\}\)</span>
<span class="math display">\[\implies x_k = \cos\left( (2k+1)\frac{\pi}{2(n+1)} \right)\ \ \ \ k \in \{ 0,1,2,\cdots,n\}\]</span></p>
<p>Therefore the zeros of <span class="math inline">\(T_{n+1}(x)\)</span> are in the interval <span class="math inline">\([-1,1]\)</span> are given by <span class="math inline">\(x_k = \cos\left( \frac{2k+1}{2n+2} \pi \right)\)</span> where <span class="math inline">\(k \in \{ 0,1,2,\cdots,n \}\)</span>. The number of zeros is also consistent with the fact that as <span class="math inline">\(T_{n+1}(x)\)</span> is an <span class="math inline">\((n+1)\)</span> th-degree polynomial, it has <span class="math inline">\((n+1)\)</span> roots. Also, these zeros are distinct.</p>
<p>These zeros are called the Chebyshev nodes of first kind. They minimise <span class="math inline">\(||w(x)||_{\infty}\)</span></p>
<p><strong>Theorem</strong></p>
<p>If <span class="math inline">\(f(x)\)</span> is smooth on <span class="math inline">\([-1,1]\)</span>, then Lagrange interpolation using the roots of Chebyshev nodes of first kind converges uniformly.</p>
<p><strong>INSERT RUNGE FUNCTION-CHEBYSHEV NODES CONVERGENCE CODE</strong></p>
</div>
</div>
</div>
<div id="wierstrass-approximation-theorem" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Wierstrass Approximation theorem<a href="interpolation.html#wierstrass-approximation-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><em>Suppose <span class="math inline">\(f\)</span> is a continuous real-valued function defined on the real interval <span class="math inline">\([a,b]\)</span>. For every <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a polynomial <span class="math inline">\(p\)</span> such that for all <span class="math inline">\(x\)</span> in <span class="math inline">\([a,b]\)</span>, we have <span class="math inline">\(|f(x) - p(x)| &lt; \epsilon\)</span>.</em></p>
<p><em><strong>Bernstein polynomial:</strong></em></p>
<p>The Bernstein basis polynomials of degree <span class="math inline">\(n\)</span> are defined as
<span class="math display">\[\begin{equation}
    b_{k,n}(x) = {}^nC_{k}\, x^k (1-x)^{n-k}
\end{equation}\]</span>
A linear combination of these basis polynomials can be used to obtain other polynomials. One of the properties of these polynomials is that
<span class="math display">\[\begin{equation}
\begin{aligned}
    \sum_{k=0}^n {b_{k,n}(x)} &amp;= \sum_{k=0}^n {{}^nC_{k}\, x^k (1-x)^{n-k}} \\
    &amp;= (x + (1 - x))^n = 1
    \label{equ:property}
\end{aligned}
\end{equation}\]</span>
So these polynomials can also be considered to act as some kind of weights. Now, for approximating functions, the Bernstein Polynomial is defined as
<span class="math display">\[\begin{equation}
    B_n(f;x) = \sum_{k=0}^n {f\left(\dfrac{k}{n}\right) {}^nC_{k}\, x^k (1-x)^{n-k}}
    \label{eqn:bern}
\end{equation}\]</span>
Here, <span class="math inline">\(f\)</span> is the function being approximated, <span class="math inline">\(n\)</span> is the order of approximation &amp; <span class="math inline">\(x\)</span> is the point at which the approximation is made.</p>
<p><strong>Proof:</strong></p>
<p>To prove the theorem on closed intervals <span class="math inline">\([a,b]\)</span>, without loss of generality, we can take the closed interval as <span class="math inline">\([0, 1]\)</span>. Thus, <span class="math inline">\(f\)</span> can be considered as a continuous real-valued function on <span class="math inline">\([0, 1]\)</span>. Since <span class="math inline">\(f\)</span> is a continuous function, we can say that for a given <span class="math inline">\(\epsilon &gt; 0\)</span>, there exists a <span class="math inline">\(\delta &gt; 0\)</span> such that:
<span class="math display">\[\begin{equation}
    |x-y| &lt; \delta \implies |f(x) - f(y)| &lt;\frac{\epsilon}{2} \ \ \ \  \forall \, x,y \in [0,1]
    \label{equ:convcond}
\end{equation}\]</span>
To prove that <span class="math inline">\(B_n(f,x)\)</span> converges to <span class="math inline">\(f(x)\)</span> uniformly, we show that <span class="math inline">\(|B_n(f,x) - f(x)|\)</span> has to be made small. By the definition of Bernstein’s polynomial, as shown in Eqn. <span class="math inline">\(\ref{eqn:bern}\)</span> and by using the property given in Eqn. <span class="math inline">\(\ref{equ:property}\)</span>, we can write <span class="math inline">\(|B_n(f;x) - f(x)|\)</span> as:
<span class="math display">\[\begin{align*}
    |B_n(f;x) - f(x)| &amp;= \left| \sum_{k=0}^n {\left(f\left(\dfrac{k}{n}\right) - f(x)\right) {}^nC_{k} \, x^k (1-x)^{n-k}} \right| \\
    &amp;\leq \sum_{k=0}^n {\left|f\left(\dfrac{k}{n}\right) - f(x)\right| {}^nC_{k} \, x^k (1-x)^{n-k}}
\end{align*}\]</span>
Now, if we consider <span class="math inline">\(y=\dfrac{k}{n}\)</span> in Eqn. <span class="math inline">\(\ref{equ:convcond}\)</span> and if <span class="math inline">\(\left|\dfrac{k}{n} - x\right| &lt; \delta\)</span>, we can say that <span class="math inline">\(\left|f\left(\dfrac{k}{n}\right) - f(x)\right| &lt; \dfrac{\epsilon}{2}\)</span>. But this is not true in the entire domain. So, we partition the domain in to two sets: <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, where <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have the following properties:
<span class="math display">\[\begin{equation}
    \begin{aligned}
        A \cup B &amp;= [0,1]\\
        A \cap B &amp;= \phi\\
        A &amp;= \{x:|k/n - x| \leq \delta, x \in [0,1]\}\\
        B &amp;= \{x:|k/n-x| &gt; \delta, x \in [0,1]\}
    \end{aligned}
    \label{equ:sets}
\end{equation}\]</span>
By dividing the domain into sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> as defined in <span class="math inline">\(\ref{equ:sets}\)</span>, we can write:
<span class="math display">\[\begin{equation*}
\begin{split}
    |B_n(f;x) - f(x)| = \sum_{x\in A} \left|f\left(\dfrac{k}{n}\right) - f(x)\right| &amp;{}^nC_{k}\, x^k (1-x)^{n-k} \\
    &amp;+ \sum_{x\in B} \left|f\left(\dfrac{k}{n}\right) - f(x)\right |{}^nC_{k}\, x^k (1-x)^{n-k}
\end{split}
\end{equation*}\]</span>
From Eqns. <span class="math inline">\(\ref{equ:convcond}\)</span> and <span class="math inline">\(\ref{equ:sets}\)</span>, we can say that <span class="math inline">\(\left|f\left(\dfrac{k}{n}\right) - f(x)\right|\)</span> has an upper bound of <span class="math inline">\(\dfrac{\epsilon}{2}\)</span> on the set <span class="math inline">\(A\)</span>. Therefore, we can write:
<span class="math display">\[\begin{equation*}
\begin{split}
    |B_n(f;x) - f(x)| \leq \sum_{x\in A} \left(\dfrac{\epsilon}{2}\right){}^nC_{k}\, x^k &amp;(1-x)^{n-k} \\
    &amp;+ \sum_{x\in B} \left|f\left(\dfrac{k}{n}\right) - f(x)\right |{}^nC_{k}\, x^k (1-x)^{n-k}
\end{split}
\end{equation*}\]</span>
By using the property described in Eqn. <span class="math inline">\(\ref{equ:property}\)</span>, we can simplify the above inequality as:
<span class="math display">\[\begin{equation*}
    |B_n(f,;x) - f(x)| \leq \frac{\epsilon}{2} + \sum_{x\in B} \left|f\left(\dfrac{k}{n}\right) - f(x)\right |{}^nC_{k}\, x^k (1-x)^{n-k}
\end{equation*}\]</span>
Since <span class="math inline">\(f\)</span> is uniformly converging in <span class="math inline">\([0,1]\)</span>, <span class="math inline">\(f\)</span> is bounded from above. So, let the maximum value of <span class="math inline">\(f\)</span> in the domain be <span class="math inline">\(M\)</span>. Thus:
<span class="math display">\[\begin{equation*}
    \text{max\{} | f(x) | \} = M \ \ \ \  \forall \, x \in [0,1]
\end{equation*}\]</span>
Thus, the maximum value <span class="math inline">\(\left|f\left(\dfrac{k}{n}\right) - f(x)\right|\)</span> can achieve in the domain is <span class="math inline">\(2M\)</span> (considering the case where, one of them is <span class="math inline">\(M\)</span> and the other is <span class="math inline">\(-M\)</span>). Thus, we have:
<span class="math display">\[\begin{equation*}
    |B_n(f;x) - f(x)| \leq \frac{\epsilon}{2} + (2M) \sum_{x\in B} {{}^nC_{k}\, x^k (1-x)^{n-k}}
\end{equation*}\]</span>
Now, in set <span class="math inline">\(B\)</span>, <span class="math inline">\(\left| \dfrac{k}{n} - x \right| &gt; \delta\)</span>. Thus, we get:
<span class="math display">\[\begin{equation*}
    \frac{\left( k/n - x \right)^2}{\delta^2} &gt; 1
\end{equation*}\]</span>
Multiplying this to the second term of RHS, we get:
<span class="math display">\[\begin{equation*}
    |B_n(f;x) - f(x)| \leq \frac{\epsilon}{2} + (2M) \sum_{x\in B} {\frac{\left( k/n - x \right)^2}{\delta^2}{}^nC_{k}\, x^k (1-x)^{n-k}}
\end{equation*}\]</span>
The second term can now be written as:
<span class="math display">\[\begin{equation*}
    \dfrac{2M}{\delta^2 n^2} \sum_{x\in B} {(k-nx)^2 \, {}^nC_{k}\, x^k (1-x)^{n-k}}
\end{equation*}\]</span>
The summation term is equivalent to computing the variance of a binomial distribution with parameters <span class="math inline">\(n\)</span> &amp; <span class="math inline">\(x\)</span>. The variance is given by <span class="math inline">\(nx(1-x)\)</span>. Thus, we get:
<span class="math display">\[\begin{equation*}
    |B_n(f;x) - f(x)| \leq \frac{\epsilon}{2} + \dfrac{2M}{\delta^2 n^2} nx(1-x)
\end{equation*}\]</span>
We know that using AM <span class="math inline">\(\geq\)</span> GM:
<span class="math display">\[\begin{equation*}
    x(1-x) \leq \dfrac{1}{4}
\end{equation*}\]</span>
Thus, we have:
<span class="math display">\[\begin{equation*}
    |B_n(f;x) - f(x)| \leq \frac{\epsilon}{2} + \dfrac{M}{2\delta^2 n}
\end{equation*}\]</span>
Now, let us define a quantity <span class="math inline">\(N\)</span> such that the above condition holds true for all <span class="math inline">\(n &gt; N\)</span>, which gives us <span class="math inline">\(\dfrac{1}{n} &lt; \dfrac{1}{N}\)</span>. Thus:
<span class="math display">\[\begin{equation*}
    |B_n(f;x) - f(x)| \leq \frac{\epsilon}{2} + \dfrac{M}{2\delta^2 N}
\end{equation*}\]</span>
If we choose the <span class="math inline">\(N\)</span> such that:
<span class="math display">\[\begin{equation*}
    \dfrac{M}{2\delta^2N} = \dfrac{\epsilon}{2}
\end{equation*}\]</span>
giving us:
<span class="math display">\[\begin{align*}
    |B_n(f;x) - f(x)| &amp;\leq \dfrac{\epsilon}{2} + \dfrac{\epsilon}{2} \\
    |B_n(f;x) - f(x)| &amp;\leq \epsilon
\end{align*}\]</span>
Thus, we have for all <span class="math inline">\(n &gt; N\)</span>, where <span class="math inline">\(N = \dfrac{M}{\delta^2\epsilon}\)</span>, we have
<span class="math display">\[\begin{equation}
    |B_n(f;x) - f(x)| \leq \epsilon
\end{equation}\]</span>
i.e., the Bernstein Polynomial <span class="math inline">\(B_n(f;x)\)</span> uniformly converges to <span class="math inline">\(f(x)\)</span> for all <span class="math inline">\(x\)</span> in the domain <span class="math inline">\([0,1]\)</span>.</p>
<p><strong>NOTE:-</strong>
1. A sequence <span class="math inline">\(\{a_n\}_{n \ge 0}\)</span> converges to <span class="math inline">\(a\)</span> <strong>algebraically</strong> if <span class="math inline">\(\exists N&gt;0\)</span> such that <span class="math inline">\(\forall \, n&gt;N\)</span>
<span class="math display">\[|a_n-a|&lt;\frac{k}{n^{\alpha}} \text{ for some } k, \,\alpha &gt;0 \]</span></p>
<p>Examples:- a. <span class="math inline">\(a_n = 1+\frac{1}{n^2}\)</span> converges to 1 algebaically as <span class="math display">\[|a_n-1| = \frac{1}{n^2}&lt;\frac{10}{n^2}\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(a_n = e^{-n}\)</span> converges to 0 algebraically as <span class="math display">\[|a_n| =e^{-n} &lt;\frac{1}{n} \ \forall n\ge 1\]</span></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><p>A sequence <span class="math inline">\(\{a_n\}_{n \ge 0}\)</span> converges to <span class="math inline">\(a\)</span> <strong>geometrically</strong> if <span class="math inline">\(\exists N&gt;0\)</span> such that <span class="math inline">\(\forall \, n&gt;N\)</span>
<span class="math display">\[|a_n-a|&lt;kc^n \text{ for some } k&gt;0 , |c|&lt;1 \]</span></p></li>
<li><p>Given any <span class="math inline">\(c\)</span> and <span class="math inline">\(\alpha\)</span> (such that <span class="math inline">\(|c|&lt;1\)</span> and <span class="math inline">\(\alpha&gt;0\)</span>), there exists <span class="math inline">\(N = N(c,\alpha)&gt;0\)</span> such that <span class="math inline">\(\forall n&gt;N\)</span></p></li>
</ol>
<p><span class="math display">\[c^n&lt;\frac{1}{n^{\alpha}}\]</span>
This implies that all geometrically convergent series are algebraically convergent.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Error in Bernstein polynomial <span class="math inline">\(B_n(x)\)</span> approximation goes down as <span class="math inline">\(\frac{1}{n}\)</span>. This means that <span class="math inline">\(B_n(x)\)</span> uniformly converges to <span class="math inline">\(f(x)\)</span> algebraically at the rate <span class="math inline">\(\frac{1}{n}\)</span>.</p></li>
<li><p>If <span class="math inline">\(f(x)\)</span> is smooth then the Chebyshev interpolant is Geometrically convergent to <span class="math inline">\(f\)</span>. This convergence is also known as Spectral Convergence.</p></li>
</ol>
<p>Consider the function <span class="math inline">\(f(x) = \frac{1}{1+25x^2}\)</span>. Let us consider the analytic continuation of <span class="math inline">\(f(x)\)</span> on a compact set <span class="math inline">\(\Omega \in \mathbb{C}^2\)</span> such that <span class="math inline">\([-1,1] \subset \Omega\)</span> which is <span class="math inline">\(\frac{1}{1+25z^2}\)</span>. This is analytic on any compact set <span class="math inline">\(\Omega\)</span> which doesn’t contain <span class="math inline">\(\pm i/5\)</span>.</p>
<!-- # Cross-references {#cross} -->
<!-- Cross-references make it easier for your readers to find and link to elements in your book. -->
<!-- ## Chapters and sub-chapters -->
<!-- There are two steps to cross-reference any heading: -->
<!-- 1. Label the heading: `# Hello world {#nice-label}`.  -->
<!--     - Leave the label off if you like the automated heading generated based on your heading title: for example, `# Hello world` = `# Hello world {#hello-world}`. -->
<!--     - To label an un-numbered heading, use: `# Hello world {-#nice-label}` or `{# Hello world .unnumbered}`. -->
<!-- 1. Next, reference the labeled heading anywhere in the text using `\@ref(nice-label)`; for example, please see Chapter \@ref(cross).  -->
<!--     - If you prefer text as the link instead of a numbered reference use: [any text you want can go here](#cross). -->
<!-- ## Captioned figures and tables -->
<!-- Figures and tables *with captions* can also be cross-referenced from elsewhere in your book using `\@ref(fig:chunk-label)` and `\@ref(tab:chunk-label)`, respectively. -->
<!-- See Figure \@ref(fig:nice-fig). -->
<!-- ```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center', fig.alt='Plot with connected points showing that vapor pressure of mercury increases exponentially as temperature increases.'} -->
<!-- par(mar = c(4, 4, .1, .1)) -->
<!-- plot(pressure, type = 'b', pch = 19) -->
<!-- ``` -->
<!-- Don't miss Table \@ref(tab:nice-tab). -->
<!-- ```{r nice-tab, tidy=FALSE} -->
<!-- knitr::kable( -->
<!--   head(pressure, 10), caption = 'Here is a nice table!', -->
<!--   booktabs = TRUE -->
<!-- ) -->
<!-- ``` -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="numerical-linear-algebra.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="quadratures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/02-Interpolation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
